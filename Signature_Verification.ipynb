{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first') ## setting image format -- \n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 4 lines)\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)))\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)))\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.maximum(basic_loss,0)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 350.02716\n"
     ]
    }
   ],
   "source": [
    "## Testing triplet loss function\n",
    "with tf.Session() as test:\n",
    "    tf.set_random_seed(1)\n",
    "    y_true = (None, None, None)\n",
    "    y_pred = (tf.random_normal([3, 128], mean=6, stddev=0.1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=1, stddev=1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=3, stddev=4, seed = 1))\n",
    "    loss = triplet_loss(y_true, y_pred)\n",
    "    \n",
    "    print(\"loss = \" + str(loss.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"danielle\"] = img_to_encoding1(\"genuine/NFI-00101001.png\", FRmodel)\n",
    "database[\"younes\"] = img_to_encoding1(\"genuine/NFI-00201002.png\", FRmodel)\n",
    "database[\"tian\"] = img_to_encoding1(\"genuine/NFI-00301003.png\", FRmodel)\n",
    "database[\"andrew\"] = img_to_encoding1(\"genuine/NFI-00401004.png\", FRmodel)\n",
    "database[\"kian\"] = img_to_encoding1(\"genuine/NFI-00501005.png\", FRmodel)\n",
    "database[\"dan\"] = img_to_encoding1(\"genuine/NFI-00601006.png\", FRmodel)\n",
    "database[\"sebastiano\"] = img_to_encoding1(\"genuine/NFI-00701007.png\", FRmodel)\n",
    "database[\"bertrand\"] = img_to_encoding1(\"genuine/NFI-00801008.png\", FRmodel)\n",
    "database[\"kevin\"] = img_to_encoding1(\"genuine/NFI-00901009.png\", FRmodel)\n",
    "# database[\"felix\"] = img_to_encoding1(\"genuine/NFI-0010010010.png\", FRmodel)\n",
    "# database[\"benoit\"] = img_to_encoding1(\"genuine/NFI-0011010011.png\", FRmodel)\n",
    "# database[\"arnaud\"] = img_to_encoding1(\"genuine/NFI-0012010012.png\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"genuine/NFI-00101001.png\"\n",
    "# image_path1 = \"images/andrew.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = cv2.imread(image_path,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ca3f01e73c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "cv2.imshow(img,'dc')\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735, 1460, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile(\"genuine/NFI-00101001.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (96,96)\n",
    "img3 = cv2.resize(img3,dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding1(image_path, model):\n",
    "    img1 = cv2.imread(image_path, 1)\n",
    "    dim = (96,96)\n",
    "    img1 = cv2.resize(img1,dim, interpolation = cv2.INTER_AREA)\n",
    "    img = img1[...,::-1]\n",
    "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11263989,  0.01372648, -0.07991041, -0.07634889,  0.14969282,\n",
       "         0.11108683,  0.10481853,  0.06506968, -0.05160766, -0.05739953,\n",
       "        -0.01849299,  0.02953503,  0.08016592,  0.05512313,  0.06567927,\n",
       "        -0.11784229,  0.05589263, -0.10627813, -0.07336158,  0.18701214,\n",
       "         0.00916011, -0.00506025,  0.08229699,  0.03794179, -0.04990904,\n",
       "        -0.07687821, -0.07512034, -0.05823411,  0.03265143, -0.02395365,\n",
       "         0.00676709, -0.08564734, -0.05395222,  0.04196445, -0.03725971,\n",
       "         0.08200329, -0.01395269,  0.19711958, -0.15951617, -0.02356524,\n",
       "         0.0414885 ,  0.1204173 , -0.14155732,  0.02384118, -0.19512586,\n",
       "         0.1286311 ,  0.02088078,  0.06298035, -0.04154909,  0.10259908,\n",
       "        -0.12373152,  0.03717515, -0.08484292,  0.00301059,  0.11761731,\n",
       "        -0.0493396 , -0.09768467,  0.1834165 , -0.03507635, -0.0665992 ,\n",
       "        -0.09797253,  0.04131002,  0.15542704, -0.14906266,  0.06773183,\n",
       "        -0.06394616,  0.06270637,  0.16180785, -0.03243063,  0.04204728,\n",
       "         0.15467907,  0.12679546,  0.03082138,  0.03889238,  0.01132765,\n",
       "         0.09134679, -0.03652287,  0.05137881,  0.09619139, -0.00444578,\n",
       "        -0.08551174,  0.01788335, -0.03784005, -0.04135755,  0.02022976,\n",
       "        -0.07697978,  0.06897613,  0.09737988,  0.06518617,  0.01754332,\n",
       "         0.11699807, -0.12034884,  0.02419494, -0.03757805,  0.01712712,\n",
       "        -0.18022463,  0.09478472, -0.04082849, -0.00369828, -0.0566254 ,\n",
       "        -0.03397631,  0.06576588, -0.00632517,  0.00131551, -0.28589976,\n",
       "         0.100408  , -0.11075341, -0.0008417 ,  0.07978711, -0.00798079,\n",
       "         0.15423796,  0.13030855, -0.06167565,  0.08457772,  0.0270312 ,\n",
       "         0.05629022, -0.10392512, -0.11547038, -0.05433349,  0.10352086,\n",
       "        -0.08444059,  0.04940734, -0.00687706,  0.15119122, -0.02670969,\n",
       "         0.0260555 , -0.01927254, -0.07539468]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_to_encoding1(image_path, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def verify(image_path, identity, database, model):\n",
    "    \"\"\"\n",
    "    Function that verifies if the person on the \"image_path\" image is \"identity\".\n",
    "    \n",
    "    Arguments:\n",
    "    image_path -- path to an image\n",
    "    identity -- string, name of the person you'd like to verify the identity. Has to be a resident of the Happy house.\n",
    "    database -- python dictionary mapping names of allowed people's names (strings) to their encodings (vectors).\n",
    "    model -- your Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "    dist -- distance between the image_path and the image of \"identity\" in the database.\n",
    "    door_open -- True, if the door should open. False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Step 1: Compute the encoding for the image. Use img_to_encoding() see example above. (≈ 1 line)\n",
    "    encoding = img_to_encoding1(image_path,model)\n",
    "    \n",
    "    # Step 2: Compute distance with identity's image (≈ 1 line)\n",
    "    dist = np.linalg.norm(encoding - database[identity])\n",
    "    \n",
    "    # Step 3: Open the door if dist < 0.7, else don't open (≈ 3 lines)\n",
    "    if dist < 0.7:\n",
    "        print(\"It's \" + str(identity) + \", welcome home!\")\n",
    "        door_open = True\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "        door_open = False\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "        \n",
    "    return dist, door_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's younes, welcome home!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46179956, True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"forged/NFI-00303002.png\", \"younes\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11420546,  0.01982441, -0.0712276 , -0.06899657,  0.1215038 ,\n",
       "         0.10826763,  0.07529756,  0.06460126, -0.07455455, -0.07774971,\n",
       "        -0.03403208,  0.05708389,  0.07577948,  0.09824125,  0.02964239,\n",
       "        -0.11762753,  0.11616983, -0.09799372, -0.05768457,  0.18233794,\n",
       "        -0.00244365,  0.03090169,  0.0842227 ,  0.074253  , -0.06741625,\n",
       "        -0.07597209, -0.00634808,  0.00791552,  0.0046156 ,  0.00217831,\n",
       "        -0.04967028, -0.09892054, -0.0170587 ,  0.07125066, -0.07000621,\n",
       "         0.0572086 ,  0.01056791,  0.18884295, -0.2117404 , -0.01884297,\n",
       "         0.01124215,  0.12979622, -0.07193897,  0.01186079, -0.1839701 ,\n",
       "         0.11278079,  0.034254  ,  0.03981133, -0.05078958,  0.14881384,\n",
       "        -0.02509809,  0.02397533, -0.07943674,  0.02678783,  0.1649583 ,\n",
       "        -0.03224923, -0.09996611,  0.17062615,  0.01702928, -0.09687789,\n",
       "        -0.0908179 ,  0.04814992,  0.12390123, -0.16496748,  0.06232051,\n",
       "        -0.0716489 ,  0.04887782,  0.13043144, -0.07984816,  0.09059832,\n",
       "         0.13527863,  0.07463416,  0.04042687,  0.03612575,  0.01447424,\n",
       "         0.10793697,  0.01329993,  0.04639699,  0.09351449, -0.03359409,\n",
       "        -0.06556776,  0.01463319, -0.00205611, -0.06131625,  0.03242485,\n",
       "        -0.11555039,  0.04674179,  0.09041905,  0.07568565,  0.08309031,\n",
       "         0.06636988, -0.14883408,  0.02314363, -0.01381682,  0.03444177,\n",
       "        -0.13420576,  0.11768342, -0.02755084, -0.00377846, -0.06564768,\n",
       "        -0.0161698 ,  0.13356276,  0.00439833,  0.03129838, -0.30570123,\n",
       "         0.06968477, -0.13818033, -0.04406312,  0.0225257 , -0.0470451 ,\n",
       "         0.16774702,  0.13497937, -0.02766253,  0.11198549,  0.00337704,\n",
       "         0.02614688, -0.07493708, -0.10936696, -0.06234165,  0.10891126,\n",
       "        -0.08247527,  0.0487242 ,  0.00652824,  0.08829799,  0.01165883,\n",
       "         0.03122548,  0.02067851, -0.10359128]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_to_encoding1(\"genuine/NFI-00102001.png\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11717176,  0.04423836, -0.11427275, -0.03848497,  0.14286608,\n",
       "         0.05382209,  0.06395762,  0.00444713,  0.00554071, -0.0871586 ,\n",
       "         0.00803049,  0.05278345,  0.0861866 ,  0.09689719, -0.00292422,\n",
       "        -0.08748735,  0.10283022, -0.10693506, -0.11507187,  0.20999338,\n",
       "         0.02240222, -0.00395892,  0.07314583,  0.0421036 , -0.02757388,\n",
       "        -0.07125108, -0.05095497, -0.01434501,  0.0224327 ,  0.03930177,\n",
       "        -0.00660794, -0.01289282, -0.01572733,  0.04408295, -0.07684384,\n",
       "         0.07413968,  0.00299342,  0.24544401, -0.14409228, -0.01436194,\n",
       "         0.00410425,  0.13664557, -0.11182234, -0.00612561, -0.15001889,\n",
       "         0.11832305,  0.01601231,  0.0328695 ,  0.01195212,  0.09618542,\n",
       "        -0.06390809,  0.10124411, -0.07943651,  0.01180394,  0.127187  ,\n",
       "        -0.07303889, -0.0930092 ,  0.13251705, -0.01785541, -0.09231742,\n",
       "        -0.09570184, -0.0072075 ,  0.12259635, -0.13481224,  0.00625706,\n",
       "        -0.0890718 ,  0.08139711,  0.19156003, -0.02500153,  0.03426458,\n",
       "         0.17513584,  0.09745094,  0.03699801,  0.01960605,  0.02553211,\n",
       "         0.09840952, -0.02260128,  0.03252774,  0.03611822,  0.03345126,\n",
       "        -0.0579004 ,  0.06482745, -0.01032139, -0.03943697,  0.04801007,\n",
       "        -0.07365248,  0.04689277,  0.09054097,  0.06931379, -0.00046961,\n",
       "         0.03912631, -0.15074833,  0.02565292, -0.01109741,  0.0109597 ,\n",
       "        -0.18949284,  0.08348695, -0.05516652,  0.00797959, -0.08766153,\n",
       "        -0.03232819,  0.06883081,  0.00820597,  0.08805735, -0.29697374,\n",
       "         0.07323442, -0.1347382 ,  0.01572794,  0.08692807, -0.02513942,\n",
       "         0.1311897 ,  0.13207717, -0.11410511,  0.14226656, -0.00491234,\n",
       "         0.04010302, -0.1402364 , -0.11986528, -0.05887217,  0.09993411,\n",
       "        -0.09665087,  0.11610002, -0.00577802,  0.12838195,  0.0101555 ,\n",
       "         0.00617585, -0.01085773, -0.07596861]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_to_encoding1(\"genuine/NFI-00103001.png\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = img_to_encoding1(\"genuine/NFI-00102001.png\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = img_to_encoding1(\"genuine/NFI-00103001.png\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([[1,2]])\n",
    "b1 = np.array([[1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.15688615e-01,  3.20313871e-02, -9.27501768e-02,\n",
       "        -5.37407696e-02,  1.32184938e-01,  8.10448602e-02,\n",
       "         6.96275905e-02,  3.45241986e-02, -3.45069170e-02,\n",
       "        -8.24541599e-02, -1.30007956e-02,  5.49336709e-02,\n",
       "         8.09830427e-02,  9.75692272e-02,  1.33590894e-02,\n",
       "        -1.02557443e-01,  1.09500021e-01, -1.02464393e-01,\n",
       "        -8.63782167e-02,  1.96165651e-01,  9.97928437e-03,\n",
       "         1.34713855e-02,  7.86842629e-02,  5.81782982e-02,\n",
       "        -4.74950634e-02, -7.36115873e-02, -2.86515281e-02,\n",
       "        -3.21474671e-03,  1.35241505e-02,  2.07400415e-02,\n",
       "        -2.81391088e-02, -5.59066832e-02, -1.63930133e-02,\n",
       "         5.76668084e-02, -7.34250247e-02,  6.56741410e-02,\n",
       "         6.78066211e-03,  2.17143476e-01, -1.77916348e-01,\n",
       "        -1.66024528e-02,  7.67319556e-03,  1.33220896e-01,\n",
       "        -9.18806568e-02,  2.86759040e-03, -1.66994482e-01,\n",
       "         1.15551919e-01,  2.51331553e-02,  3.63404155e-02,\n",
       "        -1.94187313e-02,  1.22499630e-01, -4.45030928e-02,\n",
       "         6.26097172e-02, -7.94366300e-02,  1.92958862e-02,\n",
       "         1.46072656e-01, -5.26440628e-02, -9.64876562e-02,\n",
       "         1.51571602e-01, -4.13064845e-04, -9.45976526e-02,\n",
       "        -9.32598710e-02,  2.04712078e-02,  1.23248786e-01,\n",
       "        -1.49889857e-01,  3.42887864e-02, -8.03603455e-02,\n",
       "         6.51374608e-02,  1.60995737e-01, -5.24248406e-02,\n",
       "         6.24314472e-02,  1.55207232e-01,  8.60425532e-02,\n",
       "         3.87124345e-02,  2.78658997e-02,  2.00031772e-02,\n",
       "         1.03173241e-01, -4.65067662e-03,  3.94623652e-02,\n",
       "         6.48163557e-02, -7.14138150e-05, -6.17340803e-02,\n",
       "         3.97303179e-02, -6.18875399e-03, -5.03766090e-02,\n",
       "         4.02174592e-02, -9.46014374e-02,  4.68172804e-02,\n",
       "         9.04800147e-02,  7.24997222e-02,  4.13103476e-02,\n",
       "         5.27480915e-02, -1.49791211e-01,  2.43982784e-02,\n",
       "        -1.24571156e-02,  2.27007382e-02, -1.61849290e-01,\n",
       "         1.00585185e-01, -4.13586795e-02,  2.10056594e-03,\n",
       "        -7.66546056e-02, -2.42489949e-02,  1.01196781e-01,\n",
       "         6.30214904e-03,  5.96778616e-02, -3.01337481e-01,\n",
       "         7.14595914e-02, -1.36459261e-01, -1.41675863e-02,\n",
       "         5.47268838e-02, -3.60922553e-02,  1.49468362e-01,\n",
       "         1.33528262e-01, -7.08838180e-02,  1.27126023e-01,\n",
       "        -7.67649617e-04,  3.31249461e-02, -1.07586741e-01,\n",
       "        -1.14616126e-01, -6.06069118e-02,  1.04422688e-01,\n",
       "        -8.95630717e-02,  8.24121088e-02,  3.75110889e-04,\n",
       "         1.08339973e-01,  1.09071676e-02,  1.87006649e-02,\n",
       "         4.91038617e-03, -8.97799432e-02]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a+b)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
