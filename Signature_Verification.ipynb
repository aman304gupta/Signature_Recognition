{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signature Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem Statement -** Forgery at banks has become very common and a serious crime. Here we present a deep learning model to tackle this rising problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What have we used??**\n",
    "- We have used *Convolutional Neural Networks* to extract inherent features from a sample signature.\n",
    "- For loss function we have used *Triplet Loss Function* \n",
    "- Model can be trained using *One Shot Learning* but for better results were much better with *Few shot Learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step1:** Import Dependcies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Keras have been used for simlicity of models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first') ## setting image format -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Using Pre-Trained Inception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Params:\", FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Defining Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"triplet_loss.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Triplet Loss Function:** As the name suggests we calculate difference of positive distance and negative distance. Positive Distance is calculated using anchor and positive while Negative Distance is calculated using anchor and negative image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "\n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    # distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)))\n",
    "    # distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)))\n",
    "\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
    "\n",
    "    loss = tf.maximum(basic_loss,0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 350.02716\n"
     ]
    }
   ],
   "source": [
    "## Testing triplet loss function\n",
    "with tf.Session() as test:\n",
    "    tf.set_random_seed(1)\n",
    "    y_true = (None, None, None)\n",
    "    y_pred = (tf.random_normal([3, 128], mean=6, stddev=0.1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=1, stddev=1, seed = 1),\n",
    "              tf.random_normal([3, 128], mean=3, stddev=4, seed = 1))\n",
    "    loss = triplet_loss(y_true, y_pred)\n",
    "    \n",
    "    print(\"loss = \" + str(loss.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Compiling Model & Loading Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_from_FaceNet(FRmodel):\n",
    "    ## WEIGHTS - list of all the weights names\n",
    "    weights = WEIGHTS\n",
    "    weights_dict = load_weights()\n",
    "\n",
    "    # Set layer weights of the model\n",
    "    for name in weights:\n",
    "        if FRmodel.get_layer(name) != None:\n",
    "            FRmodel.get_layer(name).set_weights(weights_dict[name])\n",
    "        elif model.get_layer(name) != None:\n",
    "            model.get_layer(name).set_weights(weights_dict[name])\n",
    "\n",
    "def load_weights():\n",
    "    # Set weights path\n",
    "    dirPath = './weights'\n",
    "    fileNames = filter(lambda f: not f.startswith('.'), os.listdir(dirPath))\n",
    "    paths = {}\n",
    "    weights_dict = {}\n",
    "\n",
    "    for n in fileNames:\n",
    "        paths[n.replace('.csv', '')] = dirPath + '/' + n\n",
    "\n",
    "    for name in WEIGHTS:\n",
    "        if 'conv' in name:\n",
    "            conv_w = genfromtxt(paths[name + '_w'], delimiter=',', dtype=None)\n",
    "            conv_w = np.reshape(conv_w, conv_shape[name])\n",
    "            conv_w = np.transpose(conv_w, (2, 3, 1, 0))\n",
    "            conv_b = genfromtxt(paths[name + '_b'], delimiter=',', dtype=None)\n",
    "            weights_dict[name] = [conv_w, conv_b]     \n",
    "        elif 'bn' in name:\n",
    "            bn_w = genfromtxt(paths[name + '_w'], delimiter=',', dtype=None)\n",
    "            bn_b = genfromtxt(paths[name + '_b'], delimiter=',', dtype=None)\n",
    "            bn_m = genfromtxt(paths[name + '_m'], delimiter=',', dtype=None)\n",
    "            bn_v = genfromtxt(paths[name + '_v'], delimiter=',', dtype=None)\n",
    "            weights_dict[name] = [bn_w, bn_b, bn_m, bn_v]\n",
    "        elif 'dense' in name:\n",
    "            dense_w = genfromtxt(dirPath+'/dense_w.csv', delimiter=',', dtype=None)\n",
    "            dense_w = np.reshape(dense_w, (128, 736))\n",
    "            dense_w = np.transpose(dense_w, (1, 0))\n",
    "            dense_b = genfromtxt(dirPath+'/dense_b.csv', delimiter=',', dtype=None)\n",
    "            weights_dict[name] = [dense_w, dense_b]\n",
    "\n",
    "    return weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)\n",
    "FRmodel.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4: Encoding Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding1(image_path, model):\n",
    "    img1 = cv2.imread(image_path, 1)\n",
    "    dim = (96,96)\n",
    "    img1 = cv2.resize(img1,dim, interpolation = cv2.INTER_AREA)\n",
    "    img = img1[...,::-1]\n",
    "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step5: Verifying model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def verify(image_path, identity, database, model):\n",
    "    \n",
    "    #encoding for the image.\n",
    "    encoding = img_to_encoding1(image_path,model)\n",
    "    # distance with identity'\n",
    "    dist = np.linalg.norm(encoding - database[identity])\n",
    "\n",
    "    if dist < 0.5:\n",
    "        print(\"It's \" + str(identity) + \", Welcome to Bank!!!\")\n",
    "        door_open = True\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", Call the Police!!!\")\n",
    "        door_open = False\n",
    "        \n",
    "    return dist, door_open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using One-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"HJC_Peshchan\"] = img_to_encoding1(\"genuine/NFI-00101001.png\", FRmodel)\n",
    "database[\"Vermututr\"] = img_to_encoding1(\"genuine/NFI-00201002.png\", FRmodel)\n",
    "database[\"Yuan\"] = img_to_encoding1(\"genuine/NFI-00301003.png\", FRmodel)\n",
    "database[\"Cbugn\"] = img_to_encoding1(\"genuine/NFI-00401004.png\", FRmodel)\n",
    "database[\"GJ\"] = img_to_encoding1(\"genuine/NFI-00501005.png\", FRmodel)\n",
    "database[\"Mary_Van_Camp\"] = img_to_encoding1(\"genuine/NFI-00601006.png\", FRmodel)\n",
    "database[\"SUruin\"] = img_to_encoding1(\"genuine/NFI-00701007.png\", FRmodel)\n",
    "database[\"Hmceycey\"] = img_to_encoding1(\"genuine/NFI-00801008.png\", FRmodel)\n",
    "database[\"Pramod\"] = img_to_encoding1(\"genuine/NFI-00901009.png\", FRmodel)\n",
    "\n",
    "database[\"Paul_J\"] = img_to_encoding1(\"genuine/NFI-02303023.png\", FRmodel)\n",
    "database[\"Myuan_Priyush\"] = img_to_encoding1(\"genuine/NFI-02404024.png\", FRmodel)\n",
    "database[\"Tanya\"] = img_to_encoding1(\"genuine/NFI-02201022.png\", FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify** for one shot learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/Genuine.png\"> Original Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/Forged.png\"> Forged Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's not HJC_Peshchan, Call the Police!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7450517, False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"forged/NFI-00301001.png\", \"HJC_Peshchan\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/Genuine1.png\"> Genuine Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's HJC_Peshchan, Welcome to Bank!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.27836695, True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"genuine/NFI-00104001.png\", \"HJC_Peshchan\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Able to detect subtle differences!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/YuanO.png\"> Original Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/YuanF.png\"> Forged Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's Yuan, Welcome to Bank!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.47795907, True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"forged/NFI-00405003.png\", \"Yuan\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/YuanG.png\"> Genuine Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's Yuan, Welcome to Bank!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46050698, True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"genuine/NFI-00302003.png\", \"Yuan\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT Able to detect subtle differences!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/VermututrO.png\"> Original Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/VermututrG.png\"> Genuine Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's Vermututr, Welcome to Bank!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46900582, True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"genuine/NFI-00203002.png\", \"Vermututr\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/VermututrF.png\"> Forged Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's not Vermututr, Call the Police!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.70124537, False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"forged/NFI-00302002.png\", \"Vermututr\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Able to detect subtle changes!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/TanyaO.png\"> Original Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/TanyaG.png\"> Genuine Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's Tanya, Welcome to Bank!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3526865, True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"genuine/NFI-02202022.png\", \"Tanya\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test_images/TanyaF.png\"> Forged Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's not Tanya, Call the Police!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5785195, False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"forged/NFI-00501022.png\", \"Tanya\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Able to detect subtle changes!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.19965357e-02,  1.07305624e-01, -2.56523583e-02,\n",
       "        -6.04756884e-02,  1.18962966e-01,  7.69163743e-02,\n",
       "         4.89022508e-02,  2.18805354e-02, -1.46911517e-01,\n",
       "        -2.68563908e-02, -3.65193188e-02, -4.46496671e-03,\n",
       "         7.35994279e-02,  5.92309702e-03,  1.83346550e-04,\n",
       "         2.09649019e-02,  7.18601719e-02, -7.76038542e-02,\n",
       "        -1.32264599e-01,  2.09488317e-01,  3.73670757e-02,\n",
       "         2.90040709e-02,  2.95063127e-02,  6.18372462e-04,\n",
       "        -6.43055588e-02,  2.64943484e-02, -1.14349715e-01,\n",
       "        -2.62366012e-02,  7.50855282e-02,  3.50988982e-03,\n",
       "        -9.75460559e-02,  6.04243912e-02, -1.03611805e-01,\n",
       "         8.91832337e-02, -6.87223598e-02,  4.55054790e-02,\n",
       "         1.57622918e-02,  2.22758129e-01, -8.24320912e-02,\n",
       "         4.59416956e-03,  1.29053220e-02,  7.23915547e-02,\n",
       "        -1.01118172e-02, -3.32452916e-02, -7.51554370e-02,\n",
       "         1.64466947e-01,  1.18728481e-01,  2.08815727e-02,\n",
       "        -1.02256209e-01,  8.74156505e-02,  5.53303659e-02,\n",
       "         7.20024109e-02, -1.55752420e-01,  6.89055771e-02,\n",
       "         1.45545036e-01, -1.09620869e-01, -4.92852507e-03,\n",
       "         6.66961744e-02,  5.79284951e-02, -1.19929522e-01,\n",
       "        -4.03204933e-03,  3.14692371e-02,  6.13571554e-02,\n",
       "        -8.59403312e-02,  3.81089263e-02, -1.11637987e-01,\n",
       "         4.87047210e-02,  1.33679092e-01,  5.96635975e-03,\n",
       "         2.99955364e-02,  9.96557996e-02,  9.91925001e-02,\n",
       "         8.33509415e-02,  7.59517178e-02,  5.18356077e-02,\n",
       "         5.40361963e-02, -1.98725499e-02,  1.40639171e-01,\n",
       "         6.10705577e-02, -2.47487836e-02,  4.02865596e-02,\n",
       "         1.17977664e-01,  1.56571735e-02, -9.76123381e-03,\n",
       "         1.02396952e-02, -4.66861688e-02,  4.81285006e-02,\n",
       "         1.23222299e-01,  5.76903522e-02,  5.14302589e-02,\n",
       "         2.06922498e-02, -1.11757308e-01, -2.17062943e-02,\n",
       "         2.27079843e-03, -7.67852217e-02, -8.98959041e-02,\n",
       "         1.42391115e-01, -6.96370006e-03,  4.39700298e-03,\n",
       "        -5.89679666e-02, -2.53661145e-02,  1.03918478e-01,\n",
       "        -3.06763779e-02,  1.82574853e-01, -2.36649618e-01,\n",
       "         2.60678343e-02, -1.67754650e-01,  9.78151038e-02,\n",
       "         5.97464666e-02, -3.89344767e-02,  1.09563231e-01,\n",
       "         1.73102543e-01, -1.22199491e-01,  1.23551480e-01,\n",
       "        -1.07771261e-02,  7.41130346e-03, -1.68523759e-01,\n",
       "        -1.39534503e-01, -1.49130926e-01,  9.90363862e-03,\n",
       "        -8.65629986e-02,  1.50452763e-01,  1.15377910e-01,\n",
       "         7.26850554e-02,  2.84948889e-02,  9.69826896e-03,\n",
       "        -5.56244738e-02, -1.42112702e-01]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_to_encoding1(\"genuine/NFI-02201022.png\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1040557 ,  0.14639431, -0.07380492, -0.09834596,  0.04153858,\n",
       "         0.11747582, -0.03230847,  0.04555031, -0.0156483 , -0.06735273,\n",
       "        -0.01550347, -0.03578096,  0.02269405, -0.00298959, -0.03529763,\n",
       "         0.01043521,  0.02132434, -0.13309786, -0.14070717,  0.15531158,\n",
       "         0.04126226,  0.07089272,  0.03167374,  0.01084924, -0.10053892,\n",
       "        -0.01308829, -0.02469324, -0.03853963,  0.01978707, -0.00459529,\n",
       "        -0.08815479, -0.0243421 , -0.05690145,  0.07646212, -0.07781163,\n",
       "         0.09322509,  0.03752657,  0.18610103, -0.11345245,  0.07004084,\n",
       "        -0.06997257,  0.04245119, -0.09933359, -0.04784032,  0.01983559,\n",
       "         0.1984514 ,  0.09372989,  0.01937401, -0.12868862,  0.16689777,\n",
       "        -0.00308439,  0.14334612, -0.11759578,  0.08946506,  0.12416398,\n",
       "        -0.08096603,  0.02606221,  0.01811345,  0.01859047, -0.13931578,\n",
       "        -0.0040506 ,  0.05017831,  0.10614674, -0.09526715, -0.03956392,\n",
       "        -0.15489021,  0.07712438,  0.19285089,  0.05657451,  0.0994212 ,\n",
       "         0.10514449,  0.038941  ,  0.02034371,  0.02292089,  0.06925685,\n",
       "         0.06306645, -0.0484712 ,  0.12332118,  0.0129399 , -0.01124636,\n",
       "         0.03679262,  0.1435186 , -0.03943245, -0.0217624 , -0.00441468,\n",
       "         0.03866751, -0.00460896,  0.06141011,  0.07197866,  0.09793225,\n",
       "         0.03229719, -0.17305376, -0.0536084 ,  0.03892547, -0.01877438,\n",
       "        -0.05135889,  0.10943783, -0.06057118,  0.02052311, -0.05011811,\n",
       "         0.01795658,  0.06282662, -0.09052713,  0.09058681, -0.24101794,\n",
       "         0.04388534, -0.1841917 ,  0.0108988 , -0.04738968, -0.03157669,\n",
       "         0.14069068,  0.1647519 , -0.07462292,  0.07456081,  0.00545527,\n",
       "         0.05350582, -0.16955441, -0.15209883, -0.07511719,  0.00260327,\n",
       "        -0.05307909,  0.13288222,  0.16504435,  0.10877549,  0.05948703,\n",
       "        -0.00472249,  0.0320701 , -0.1154303 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img_to_encoding1(\"forged/NFI-00401003.png\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11717176,  0.04423836, -0.11427275, -0.03848497,  0.14286608,\n",
       "         0.05382209,  0.06395762,  0.00444713,  0.00554071, -0.0871586 ,\n",
       "         0.00803049,  0.05278345,  0.0861866 ,  0.09689719, -0.00292422,\n",
       "        -0.08748735,  0.10283022, -0.10693506, -0.11507187,  0.20999338,\n",
       "         0.02240222, -0.00395892,  0.07314583,  0.0421036 , -0.02757388,\n",
       "        -0.07125108, -0.05095497, -0.01434501,  0.0224327 ,  0.03930177,\n",
       "        -0.00660794, -0.01289282, -0.01572733,  0.04408295, -0.07684384,\n",
       "         0.07413968,  0.00299342,  0.24544401, -0.14409228, -0.01436194,\n",
       "         0.00410425,  0.13664557, -0.11182234, -0.00612561, -0.15001889,\n",
       "         0.11832305,  0.01601231,  0.0328695 ,  0.01195212,  0.09618542,\n",
       "        -0.06390809,  0.10124411, -0.07943651,  0.01180394,  0.127187  ,\n",
       "        -0.07303889, -0.0930092 ,  0.13251705, -0.01785541, -0.09231742,\n",
       "        -0.09570184, -0.0072075 ,  0.12259635, -0.13481224,  0.00625706,\n",
       "        -0.0890718 ,  0.08139711,  0.19156003, -0.02500153,  0.03426458,\n",
       "         0.17513584,  0.09745094,  0.03699801,  0.01960605,  0.02553211,\n",
       "         0.09840952, -0.02260128,  0.03252774,  0.03611822,  0.03345126,\n",
       "        -0.0579004 ,  0.06482745, -0.01032139, -0.03943697,  0.04801007,\n",
       "        -0.07365248,  0.04689277,  0.09054097,  0.06931379, -0.00046961,\n",
       "         0.03912631, -0.15074833,  0.02565292, -0.01109741,  0.0109597 ,\n",
       "        -0.18949284,  0.08348695, -0.05516652,  0.00797959, -0.08766153,\n",
       "        -0.03232819,  0.06883081,  0.00820597,  0.08805735, -0.29697374,\n",
       "         0.07323442, -0.1347382 ,  0.01572794,  0.08692807, -0.02513942,\n",
       "         0.1311897 ,  0.13207717, -0.11410511,  0.14226656, -0.00491234,\n",
       "         0.04010302, -0.1402364 , -0.11986528, -0.05887217,  0.09993411,\n",
       "        -0.09665087,  0.11610002, -0.00577802,  0.12838195,  0.0101555 ,\n",
       "         0.00617585, -0.01085773, -0.07596861]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img_to_encoding1(\"genuine/NFI-00103001.png\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = img_to_encoding1(\"genuine/NFI-00102001.png\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = img_to_encoding1(\"genuine/NFI-00103001.png\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1 = np.array([[1,2]])\n",
    "# b1 = np.array([[1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.15688615e-01,  3.20313871e-02, -9.27501768e-02,\n",
       "        -5.37407696e-02,  1.32184938e-01,  8.10448602e-02,\n",
       "         6.96275905e-02,  3.45241986e-02, -3.45069170e-02,\n",
       "        -8.24541599e-02, -1.30007956e-02,  5.49336709e-02,\n",
       "         8.09830427e-02,  9.75692272e-02,  1.33590894e-02,\n",
       "        -1.02557443e-01,  1.09500021e-01, -1.02464393e-01,\n",
       "        -8.63782167e-02,  1.96165651e-01,  9.97928437e-03,\n",
       "         1.34713855e-02,  7.86842629e-02,  5.81782982e-02,\n",
       "        -4.74950634e-02, -7.36115873e-02, -2.86515281e-02,\n",
       "        -3.21474671e-03,  1.35241505e-02,  2.07400415e-02,\n",
       "        -2.81391088e-02, -5.59066832e-02, -1.63930133e-02,\n",
       "         5.76668084e-02, -7.34250247e-02,  6.56741410e-02,\n",
       "         6.78066211e-03,  2.17143476e-01, -1.77916348e-01,\n",
       "        -1.66024528e-02,  7.67319556e-03,  1.33220896e-01,\n",
       "        -9.18806568e-02,  2.86759040e-03, -1.66994482e-01,\n",
       "         1.15551919e-01,  2.51331553e-02,  3.63404155e-02,\n",
       "        -1.94187313e-02,  1.22499630e-01, -4.45030928e-02,\n",
       "         6.26097172e-02, -7.94366300e-02,  1.92958862e-02,\n",
       "         1.46072656e-01, -5.26440628e-02, -9.64876562e-02,\n",
       "         1.51571602e-01, -4.13064845e-04, -9.45976526e-02,\n",
       "        -9.32598710e-02,  2.04712078e-02,  1.23248786e-01,\n",
       "        -1.49889857e-01,  3.42887864e-02, -8.03603455e-02,\n",
       "         6.51374608e-02,  1.60995737e-01, -5.24248406e-02,\n",
       "         6.24314472e-02,  1.55207232e-01,  8.60425532e-02,\n",
       "         3.87124345e-02,  2.78658997e-02,  2.00031772e-02,\n",
       "         1.03173241e-01, -4.65067662e-03,  3.94623652e-02,\n",
       "         6.48163557e-02, -7.14138150e-05, -6.17340803e-02,\n",
       "         3.97303179e-02, -6.18875399e-03, -5.03766090e-02,\n",
       "         4.02174592e-02, -9.46014374e-02,  4.68172804e-02,\n",
       "         9.04800147e-02,  7.24997222e-02,  4.13103476e-02,\n",
       "         5.27480915e-02, -1.49791211e-01,  2.43982784e-02,\n",
       "        -1.24571156e-02,  2.27007382e-02, -1.61849290e-01,\n",
       "         1.00585185e-01, -4.13586795e-02,  2.10056594e-03,\n",
       "        -7.66546056e-02, -2.42489949e-02,  1.01196781e-01,\n",
       "         6.30214904e-03,  5.96778616e-02, -3.01337481e-01,\n",
       "         7.14595914e-02, -1.36459261e-01, -1.41675863e-02,\n",
       "         5.47268838e-02, -3.60922553e-02,  1.49468362e-01,\n",
       "         1.33528262e-01, -7.08838180e-02,  1.27126023e-01,\n",
       "        -7.67649617e-04,  3.31249461e-02, -1.07586741e-01,\n",
       "        -1.14616126e-01, -6.06069118e-02,  1.04422688e-01,\n",
       "        -8.95630717e-02,  8.24121088e-02,  3.75110889e-04,\n",
       "         1.08339973e-01,  1.09071676e-02,  1.87006649e-02,\n",
       "         4.91038617e-03, -8.97799432e-02]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (a+b)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
